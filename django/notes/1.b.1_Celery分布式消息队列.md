[TOC]

# Celery分布式消息队列
官网：https://docs.celeryq.dev/en/stable/

## 基础介绍
1. 简介
    Celery 是一个异步任务队列/基于分布式消息传递的作业队列。其本质是生产者和消费者模式。生产者发送任务到消息队列，消费者负责处理任务。

2. 应用场景
    - web应用：当用户在网站进行某个操作需要很长时间完成时，我们可以将这种操作交给Celery执行，比如发送邮件
    - 任务场景：比如在运维场景下需要批量在几百台机器执行某些命令或者任务
    - 定时任务：定时导数据报表、定时发送通知类似场景

1. Celery 的架构
    - Celery的架构由三部分组成：**消息中间件(Broker)**、**任务执行单元Worker**、**结果存储(Backend)**。
        - 消息中间件Broker：支持RabbitMQ、Redis、Amazon SQS、MongoDB、Memcached 等，官方推荐RabbitMQ
        - 任务执行单元Worker：负责从消息队列中取出任务执行，它可以启动一个或者多个，也可以启动在不同的机器节点，这就是其实现分布式的核心。
        - 结果存储Backend：支持RabbitMQ、 Redis、Memcached,SQLAlchemy, Django ORM、Apache Cassandra、Elasticsearch


    celery 架构图
    ![图 1](../statics/1.b.1_Celery%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-celery%20%E6%9E%B6%E6%9E%84%E5%9B%BE.png)  

3. celery 工作原理
    1. 任务模块Task包含异步任务和定时任务。
        - **异步任务通常在业务逻辑中被触发并发往消息队列，**
        - 定时任务由Celery Beat进程周期性地将任务发往消息队列
    2. 任务执行单元Worker实时监视消息队列获取队列中的任务执行
    3. Woker执行完任务后将结果保存在Backend中

## celery 在 Django 中的使用

1. 安装
    由于celery是有python开发，所以可以使用pip包管理工具直接下载
    > pip install celery

2. 使用
    建议将 celery 相关配置放在单独的文件夹中
    官方教程：https://docs.celeryq.dev/en/stable/django/first-steps-with-django.html

    > **1.定义 Celery 包**

    ![图 2](../statics/1.b.1_Celery%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%AE%9A%E4%B9%89%20Celery%20%20%E5%8C%85.png)  

    > **2.创建Celery实例**

    ![图 3](../statics/1.b.1_Celery%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%88%9B%E5%BB%BACelery%E5%AE%9E%E4%BE%8B.png)  

    > `celery_tasks.main.py`

    ```py
    from celery import Celery

    # 0.为celery使用django配置文件进行设置
    import os
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'meiduo_mall.settings')

    # 1.创建celery实例
    celery_app = Celery('celery_tasks')
    ```

    > **3.配置Celery 与 加载配置信息**

    ![图 4](../statics/1.b.1_Celery%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E9%85%8D%E7%BD%AECelery.png)  

    > `celery_tasks.config.py`

    ```py
    # 中间人（broker）配置信息
    broker_url = "redis://127.0.0.1:6379/15"
    ```

    更多可配置参数：https://docs.celeryq.dev/en/stable/userguide/configuration.html?highlight=broker#new-lowercase-settings

    > 加载配置信息
    > `celery_tasks.main.py`

    ```py
    # 2.设置broker
    # 通过加载配置文件的方式设置broker
    celery_app.config_from_object('celery_tasks.config')
    ```

    > **4.定义任务**

    ![图 5](../statics/1.b.1_Celery%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%AE%9A%E4%B9%89%E4%BB%BB%E5%8A%A1.png)  

    - 1.注册任务
        > `celery_tasks.main.py`

        ```py
        # 3.celery自动检测指定包的任务
        # autodiscover_tasks 参数是列表
        # 列表中的元素是 tasks的路径
        celery_app.autodiscover_tasks(['celery_tasks.sms'])
        ```
    - 2.定义任务
        > celery_tasks.sms.tasks.py

        ```py
        # 生产者 —— 任务（函数）
        # 1. 这个函数 必须要用 celery的实例的 task装饰器装饰
        # 2. 需要celery 自动检测指定的包的任务

        from celery_tasks.main import celery_app
        import logging

        logger = logging.getLogger('django')

        # name：异步任务别名
        @celery_app.task(name = 'send_sms_code')
        def celery_send_sms_code(mobile, sms_code):
            """
            发送短信异步任务
            :param mobile: 手机号
            :param sms_code: 短信验证码
            """
            logger.info("%s 的验证码为 %s" % (mobile, sms_code))
            print("验证码为 %s" % sms_code)
        ```

        关于装饰器可用参数，见 
        https://docs.celeryq.dev/en/latest/userguide/tasks.html#task-options

    - 3.启动Celery服务
        > cd ~/meiduo_project/meiduo_mall
        > celery -A celery_tasks.main worker -l INFO

        > - -A 指对应的应用程序, 其参数是项目中 Celery实例的位置。
        > - worker 指这里要启动的worker。
        > - -l 指日志等级，比如INFO等级。

        ![图 6](../statics/1.b.1_Celery%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%90%AF%E5%8A%A8Celery%E6%9C%8D%E5%8A%A1.png)  

    - 4.调用定义的任务
        ```py
        # 发送短信验证码
        from celery_tasks.sms.tasks import celery_send_sms_code
        celery_send_sms_code.delay(mobile, sms_code)
        ```

    - 5.补充说明 celery worker 的工作模式
        - 默认是进程池方式，进程数以当前机器的CPU核数为参考，每个CPU开四个进程。
        - 如何自己指定进程数： `celery worker -A proj --concurrency=4`
        - 如何改变进程池方式为协程方式： `celery worker -A proj --concurrency=1000 -P eventlet -c 1000`

        > #安装eventlet模块
        > $ pip install eventlet
        > 
        > #启用 Eventlet 池
        > $ celery -A celery_tasks.main worker -l info -P eventlet -c 1000
